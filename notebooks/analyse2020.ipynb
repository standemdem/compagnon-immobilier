{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a15375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape brut: (3522416, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Charger\n",
    "df = pd.read_csv(r\"../data/raw/full_2020.csv\", low_memory=False)\n",
    "print(\"Shape brut:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932aeca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape brut: (3522416, 40)\n",
      "Shape après nettoyage: (840758, 42)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) CHARGEMENT & NETTOYAGE DE BASE\n",
    "# - Garde uniquement les VENTES\n",
    "# - Transforme la date et crée annee/mois\n",
    "# - Convertit les colonnes numériques clés\n",
    "# - Supprime les valeurs impossibles\n",
    "# - Trim \"doux\" des outliers via prix/m² (1e–99e pct)\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(\"Shape brut:\", df.shape)\n",
    "\n",
    "# Garder uniquement les ventes\n",
    "if \"nature_mutation\" in df.columns:\n",
    "    df = df[df[\"nature_mutation\"].astype(str).str.lower().str.contains(\"vente\", na=False)]\n",
    "\n",
    "# Dates -> annee, mois\n",
    "if \"date_mutation\" in df.columns:\n",
    "    df[\"date_mutation\"] = pd.to_datetime(df[\"date_mutation\"], errors=\"coerce\")\n",
    "    df[\"annee\"] = df[\"date_mutation\"].dt.year\n",
    "    df[\"mois\"]  = df[\"date_mutation\"].dt.month\n",
    "\n",
    "# Colonnes numériques importantes\n",
    "for col in [\"valeur_fonciere\",\"surface_reelle_bati\",\"surface_terrain\",\n",
    "            \"nombre_pieces_principales\",\"longitude\",\"latitude\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# onléve les Valeurs impossibles\n",
    "\n",
    "if \"valeur_fonciere\" in df.columns:\n",
    "    df = df[df[\"valeur_fonciere\"] > 0]\n",
    "if \"surface_reelle_bati\" in df.columns:\n",
    "    df = df[df[\"surface_reelle_bati\"] > 0]\n",
    "if \"surface_terrain\" in df.columns:\n",
    "    df = df[df[\"surface_terrain\"] >= 0]\n",
    "\n",
    "# (on enlève juste les 1% les plus bas et les 1% les plus hauts) garde 98% des ventes normales\n",
    "if {\"valeur_fonciere\",\"surface_reelle_bati\"}.issubset(df.columns):\n",
    "    prix_m2 = df[\"valeur_fonciere\"] / df[\"surface_reelle_bati\"].replace(0, np.nan)\n",
    "    q1, q99 = prix_m2.quantile([0.01, 0.99])\n",
    "    df = df[(prix_m2 >= q1) & (prix_m2 <= q99)]\n",
    "\n",
    "print(\"Shape après nettoyage:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e6fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) LOCALISATION SIMPLE SANS MODÈLE\n",
    "# - Normalise code_postal (ex : 1250.0 -> \"01250\")\n",
    "# - Crée departement = 2 premiers chiffres du code postal\n",
    "# - Ajoute commune_freq = nb de ventes par commune\n",
    "# - Supprime longitude/latitude et geo_cluster\n",
    "# =========================\n",
    "\n",
    "# Code postal propre sur 5 caractères\n",
    "if \"code_postal\" in df.columns:\n",
    "    df[\"code_postal\"] = pd.to_numeric(df[\"code_postal\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"code_postal\"] = df[\"code_postal\"].astype(str).str.zfill(5)\n",
    "else:\n",
    "    df[\"code_postal\"] = np.nan\n",
    "\n",
    "# Département = 2 premiers chiffres\n",
    "df[\"departement\"] = df[\"code_postal\"].str[:2]\n",
    "\n",
    "# Fréquence de ventes par commune\n",
    "if \"nom_commune\" in df.columns:\n",
    "    commune_freq = df[\"nom_commune\"].value_counts()\n",
    "    df[\"commune_freq\"] = df[\"nom_commune\"].map(commune_freq).astype(\"float32\")\n",
    "else:\n",
    "    df[\"commune_freq\"] = np.nan\n",
    "\n",
    "# Supprime les coordonnées (choix de simplicité)\n",
    "if {\"longitude\",\"latitude\"}.issubset(df.columns):\n",
    "    df = df.drop(columns=[\"longitude\",\"latitude\"])\n",
    "\n",
    "# Supprime geo_cluster si présent\n",
    "if \"geo_cluster\" in df.columns:\n",
    "    df = df.drop(columns=[\"geo_cluster\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0527bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) FEATURES SUPPLÉMENTAIRES LÉGÈRES\n",
    "# - log_surface \n",
    "# - densite_pieces = pièces / surface\n",
    "# =========================\n",
    "#On calcule le nombre de pièces par m².\n",
    "df[\"log_surface_reelle_bati\"] = np.log1p(df[\"surface_reelle_bati\"])\n",
    "df[\"densite_pieces\"] = df[\"nombre_pieces_principales\"] / df[\"surface_reelle_bati\"]\n",
    "df[\"densite_pieces\"] = df[\"densite_pieces\"].replace([np.inf, -np.inf], np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) SÉLECTION DES FEATURES\n",
    "# =========================\n",
    "\n",
    "candidate_features = [\n",
    "    \"log_surface_reelle_bati\",\n",
    "    \"densite_pieces\",\n",
    "    \"nombre_pieces_principales\",\n",
    "    \"surface_terrain\",\n",
    "    \"type_local\",\n",
    "    \"departement\",\n",
    "    \"commune_freq\",\n",
    "    \"annee\", \"mois\"\n",
    "]\n",
    "\n",
    "feature_cols = [c for c in candidate_features if c in df.columns]\n",
    "df_model = df.dropna(subset=[\"valeur_fonciere\"]).copy()\n",
    "X = df_model[feature_cols].copy()\n",
    "y = df_model[\"valeur_fonciere\"].astype(float).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) PRÉPARATION & ENCODAGE\n",
    "# - Catégorielles : OneHot (type_local, departement)\n",
    "# - Numériques : pass-through\n",
    "# =========================\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "cat_cols = [c for c in [\"type_local\",\"departement\"] if c in X.columns]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# Cast\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"string\")\n",
    "for c in num_cols:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "#nepastransformerlesnum\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", \"passthrough\", num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c6389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille entraînement après downsample : 120000\n",
      "Fit terminé en 10.3 s\n",
      "MAE : 393608.92 | RMSE : 4337603.09 | R² : 0.1868\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "# =========================\n",
    "# 6) ENTRAÎNEMENT RANDOM FOREST\n",
    "# =========================\n",
    "\n",
    "max_rows = 120_000\n",
    "if len(X) > max_rows:\n",
    "    idx = np.random.RandomState(42).choice(X.index, size=max_rows, replace=False)\n",
    "    X = X.loc[idx].copy()\n",
    "    y = y.loc[idx].copy()\n",
    "print(\"Taille entraînement après downsample :\", len(X))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=80,       \n",
    "    max_depth=18,         \n",
    "    max_features=\"sqrt\",  \n",
    "    bootstrap=True,\n",
    "    max_samples=0.65,     \n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = Pipeline([(\"prep\", preprocess), (\"rf\", rf)])\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "model.fit(X_train, np.log1p(y_train))\n",
    "print(\"Fit terminé en\", round(time.time()-t0,1), \"s\")\n",
    "\n",
    "# Prédictions & métriques\n",
    "y_pred = np.expm1(model.predict(X_test))\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MAE :\", round(mae,2), \"| RMSE :\", round(rmse,2), \"| R² :\", round(r2,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f72ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmenter la taille du downsample → 200k ou 300k lignes .\n",
    "\n",
    "#Augmenter (n_estimators=200) et augmenter max_depth (20–25).\n",
    "\n",
    "#ajouter plus de features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
