import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from pathlib import Path

st.set_page_config(
    page_title="EDA 2 ‚Äî D√©marche de nettoyage (Avant / Apr√®s)",
    page_icon="üßº",
    layout="wide"
)

# --------------------------------------------------
# Paths
# --------------------------------------------------
PATH_BEFORE = Path("data/parquet/optimized_2020.parquet")
PATH_AFTER = Path("data/processed/dvf_appartements_vente_2020.parquet.gz")

# --------------------------------------------------
# Loaders
# --------------------------------------------------
@st.cache_data(show_spinner=False)
def load_before(path: Path) -> pd.DataFrame:
    df = pd.read_parquet(path)

    cols = [
        "id_mutation",
        "nature_mutation",
        "type_local",
        "valeur_fonciere",
        "surface_reelle_bati",
        "latitude",
        "longitude",
    ]
    cols = [c for c in cols if c in df.columns]
    df = df[cols].copy()

    # Filtrage coh√©rent avec l‚ÄôEDA initiale
    df = df[df["nature_mutation"] == "Vente"]
    df = df[df["surface_reelle_bati"].fillna(0) > 0]

    df["prix_m2"] = df["valeur_fonciere"] / df["surface_reelle_bati"]
    return df


@st.cache_data(show_spinner=False)
def load_after(path: Path) -> pd.DataFrame:
    df = pd.read_parquet(path)
    df = df[df["surface_reelle_bati"].fillna(0) > 0]
    df["prix_m2"] = df["valeur_fonciere"] / df["surface_reelle_bati"]
    return df


def kpis(df: pd.DataFrame) -> dict:
    return {
        "lignes": len(df),
        "mutations": df["id_mutation"].nunique(),
        "prix_m2_med": df["prix_m2"].median(),
        "prix_m2_q95": df["prix_m2"].quantile(0.95),
    }


# --------------------------------------------------
# Page
# --------------------------------------------------
st.title("üßº D√©marche de nettoyage orient√©e Machine Learning")
st.caption(
    "Cette section pr√©sente l‚Äôimpact du nettoyage des donn√©es DVF √† travers une comparaison "
    "entre le dataset initial et le dataset final utilis√© pour la mod√©lisation."
)

df_before = load_before(PATH_BEFORE)
df_after = load_after(PATH_AFTER)

kb = kpis(df_before)
ka = kpis(df_after)

tab1, tab2, tab3, tab4, tab5 = st.tabs(["Constat initial", "M√©thodologie", 
                                  "R√©gles m√©tier", "Avant / Apr√®s nettoyage", "Conclusion"])

# --------------------------------------------------
# Constat initial
# --------------------------------------------------
with tab1:
    st.markdown(
        """
    ## 1Ô∏è‚É£ Constat initial : limites du dataset DVF brut

    L‚Äôexploration du dataset DVF dans sa forme brute met en √©vidence plusieurs limites structurelles :

    - une **mutation** peut regrouper plusieurs lignes de transaction,
    - ces lignes peuvent correspondre √† **plusieurs types de biens**,
    - une mutation peut inclure **plusieurs appartements**,
    - la valeur fonci√®re est exprim√©e **au niveau de la mutation**, et non du lot.

    üëâ **Cons√©quence m√©thodologique** :  
    le calcul na√Øf d‚Äôun prix au m¬≤ conduit √† une **variable cible ambigu√´**, incompatible avec une mod√©lisation fiable.
    """
    )

    st.info(
        "Dans cet √©tat, l‚Äôapprentissage d‚Äôun mod√®le de pr√©diction reviendrait √† apprendre sur "
        "des observations dont la cible n‚Äôest pas clairement d√©finie."
    )

# --------------------------------------------------
# Objectif m√©thodologique
# --------------------------------------------------
with tab2:
    st.markdown(
        """
    ## 2Ô∏è‚É£ Objectif m√©thodologique du nettoyage

    Le nettoyage des donn√©es vise √† **poser correctement le probl√®me de machine learning**.

    Le dataset recherch√© doit satisfaire les propri√©t√©s suivantes :
    - chaque observation repr√©sente **un bien immobilier unique**,
    - les biens sont **comparables entre eux**,
    - la variable cible (prix au m¬≤) est **d√©finie sans ambigu√Øt√©**,
    - les r√®gles de s√©lection sont **explicites, justifi√©es et reproductibles**.
    """
    )

# --------------------------------------------------
# R√®gles m√©tier
# --------------------------------------------------
with tab3:
    st.markdown(
        """
    ## 3Ô∏è‚É£ R√®gles m√©tier appliqu√©es

    Les r√®gles suivantes sont issues de l‚Äôanalyse exploratoire :

    **1. Restriction aux mutations de type *Vente***  
    ‚Üí L‚Äôobjectif est de mod√©liser le fonctionnement du march√© immobilier.

    **2. Restriction au p√©rim√®tre des appartements**  
    ‚Üí Le m√©lange de biens structurellement diff√©rents (maisons, locaux, d√©pendances) augmente artificiellement la variance.

    **3. Exclusion des mutations mixtes**  
    ‚Üí Les mutations combinant appartements et autres types de biens ne sont pas comparables.

    **4. R√®gle centrale : *1 mutation = 1 appartement***  
    ‚Üí Cette contrainte garantit une correspondance non ambigu√´ entre la mutation et le bien mod√©lis√©.

    **5. Conservation d‚Äôinformations mutationnelles sous forme de variables explicatives**  
    ‚Üí Exemple : pr√©sence d‚Äôune d√©pendance.
    """
    )

# --------------------------------------------------
# KPIs
# --------------------------------------------------
with tab4:
    st.markdown(
        """
    ## 4Ô∏è‚É£ R√©sultats quantitatifs du nettoyage    
    """
    )
    st.subheader("üìä Indicateurs globaux ‚Äî Avant / Apr√®s nettoyage")

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Lignes (avant)", f"{kb['lignes']:,}".replace(",", " "))
    c2.metric("Mutations (avant)", f"{kb['mutations']:,}".replace(",", " "))
    c3.metric("Lignes (apr√®s)", f"{ka['lignes']:,}".replace(",", " "))
    c4.metric("Mutations (apr√®s)", f"{ka['mutations']:,}".replace(",", " "))

    c1, c2 = st.columns(2)
    c1.metric("Prix/m¬≤ m√©dian (avant)", f"{kb['prix_m2_med']:.0f} ‚Ç¨")
    c2.metric("Prix/m¬≤ m√©dian (apr√®s)", f"{ka['prix_m2_med']:.0f} ‚Ç¨")

    # --------------------------------------------------
    # Distributions
    # --------------------------------------------------
    st.markdown(
        """
    

    Apr√®s nettoyage, la distribution du prix au m¬≤ devient plus resserr√©e et plus coh√©rente,
    ce qui traduit une r√©duction significative de l‚Äôh√©t√©rog√©n√©it√©.

    Afin de pr√©server la lisibilit√©, les distributions sont tronqu√©es au 99·µâ percentile.
    """
    )

    q_before = df_before["prix_m2"].quantile(0.99)
    q_after = df_after["prix_m2"].quantile(0.99)

    fig1 = px.histogram(
        df_before[df_before["prix_m2"] <= q_before],
        x="prix_m2",
        nbins=80,
        title="Avant nettoyage ‚Äî distribution √©tal√©e et bruit√©e"
    )
    st.plotly_chart(fig1, width="stretch")

    fig2 = px.histogram(
        df_after[df_after["prix_m2"] <= q_after],
        x="prix_m2",
        nbins=80,
        title="Apr√®s nettoyage ‚Äî distribution stabilis√©e"
    )
    st.plotly_chart(fig2, width="stretch")

    # --------------------------------------------------
    # Types de biens
    # --------------------------------------------------
    st.markdown(
        """
        La comparaison suivante illustre la transition d‚Äôun dataset h√©t√©rog√®ne
        vers un p√©rim√®tre strictement d√©fini.
        """
    )

    c1, c2 = st.columns(2)

    with c1:
        vc = df_before["type_local"].value_counts(normalize=True).mul(100).reset_index()
        vc.columns = ["type_local", "pct"]
        fig = px.bar(vc, x="type_local", y="pct", title="Avant nettoyage ‚Äî mix des types de biens")
        st.plotly_chart(fig, width="stretch")

    with c2:
        vc = df_after["type_local"].value_counts(normalize=True).mul(100).reset_index()
        vc.columns = ["type_local", "pct"]
        fig = px.bar(vc, x="type_local", y="pct", title="Apr√®s nettoyage ‚Äî p√©rim√®tre ma√Ætris√©")
        st.plotly_chart(fig, width="stretch")

# --------------------------------------------------
# Conclusion
# --------------------------------------------------
with tab5:
    st.warning(
        """
    Cette √©tape de nettoyage transforme le probl√®me initial :

    - d‚Äôun ensemble de transactions h√©t√©rog√®nes et ambigu√´s,
    - vers un dataset coh√©rent, comparable et exploitable en machine learning.

    Le dataset obtenu constitue la base :
    - du *feature engineering*,
    - de l‚Äôentra√Ænement du mod√®le de pr√©diction du prix au m¬≤,
    - et de l‚Äôinterface de d√©monstration pr√©sent√©e dans l‚Äôapplication.
    """
    )
