import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px

st.set_page_config(page_title="Exploration na√Øve ‚Äî DVF", layout="wide")

# =========================
# Helpers
# =========================
@st.cache_data
def load_parquet(path: str) -> pd.DataFrame:
    return pd.read_parquet(path)

def format_int(n: int) -> str:
    return f"{n:,}".replace(",", " ")

def memory_mb(df: pd.DataFrame) -> float:
    return float(df.memory_usage(deep=True).sum() / 1e6)

def top_missing(df: pd.DataFrame, k: int = 20) -> pd.DataFrame:
    s = df.isna().mean().sort_values(ascending=False) * 100
    out = s.head(k).round(2).reset_index()
    out.columns = ["colonne", "taux_manquant_%"]
    return out

def df_schema(df: pd.DataFrame) -> pd.DataFrame:
    out = pd.DataFrame({
        "colonne": df.columns,
        "type": df.dtypes.astype(str),
        "taux_manquant_%": (df.isna().mean() * 100).round(2),
        "nb_uniques": df.nunique(dropna=True).values
    })
    return out

def safe_sample(df: pd.DataFrame, n: int, seed: int = 42) -> pd.DataFrame:
    if len(df) <= n:
        return df
    return df.sample(n=n, random_state=seed)

# =========================
# Sidebar
# =========================
st.sidebar.header("‚öôÔ∏è Param√®tres")

default_path = "data/parquet/optimized_2020.parquet"
data_path = st.sidebar.text_input("Chemin du dataset DVF brut (.parquet)", value=default_path)

sample_n = st.sidebar.slider(
    "√âchantillon pour les graphes (pour √©viter de tout charger en m√©moire)",
    min_value=5_000, max_value=200_000, value=50_000, step=5_000
)

top_k_modalities = st.sidebar.slider(
    "Top modalit√©s (cat√©gorielles)",
    min_value=5, max_value=50, value=15, step=1
)

st.sidebar.markdown("---")
show_preview = st.sidebar.checkbox("Afficher un aper√ßu (head)", value=True)
preview_rows = st.sidebar.slider("Nombre de lignes dans l'aper√ßu", 5, 50, 15)

# =========================
# Load data
# =========================
try:
    df = load_parquet(data_path)
except Exception as e:
    st.error(f"Impossible de charger le fichier : {data_path}\n\nErreur : {e}")
    st.stop()

# =========================
# Title / Intro
# =========================
st.title("üîç Exploration na√Øve des donn√©es DVF (brutes)")
st.markdown(
    """
    Cette page pr√©sente une **premi√®re lecture descriptive** des donn√©es DVF, avant tout filtrage,
    agr√©gation ou choix de variables.  
    L‚Äôobjectif est de **comprendre la structure** du dataset : volume, types de variables, valeurs manquantes,
    variables quantitatives et cat√©gorielles.
    """
)
tab1, tab2, tab3, tab4, tab5 = st.tabs(["Vue d'ensemble", "Structure", "Variables quantitatives", "Variables cat√©gorielles", "Constats"])
# =========================
# Section 1 ‚Äî Overview
# =========================
st.divider()
with tab1:
    st.header("1) Vue d‚Äôensemble")

    # Colonnes num√©riques / cat√©gorielles
    num_cols = df.select_dtypes(include=["number"]).columns.tolist()
    cat_cols = df.select_dtypes(include=["object", "bool", "category"]).columns.tolist()

    # Mutations
    nb_mutations = df["id_mutation"].nunique() if "id_mutation" in df.columns else None

    # Valeur fonci√®re min/max
    vf_min, vf_max = None, None
    if "valeur_fonciere" in df.columns:
        vf_min = df["valeur_fonciere"].min(skipna=True)
        vf_max = df["valeur_fonciere"].max(skipna=True)

    # Max lignes par mutation
    max_lines_per_mut = None
    if "id_mutation" in df.columns:
        max_lines_per_mut = df.groupby("id_mutation").size().max()

    # Affichage KPI
    k1, k2, k3, k4 = st.columns(4)
    with k1:
        st.metric("Lignes", format_int(df.shape[0]))
    with k2:
        st.metric("Colonnes", format_int(df.shape[1]))
    with k3:
        st.metric("Colonnes num√©riques", format_int(len(num_cols)))
    with k4:
        st.metric("Colonnes cat√©gorielles", format_int(len(cat_cols)))

    k5, k6, k7, k8 = st.columns(4)
    with k5:
        st.metric("Mutations uniques", format_int(nb_mutations) if nb_mutations is not None else "‚Äî")
    with k6:
        st.metric(
            "Valeur fonci√®re min",
            f"{vf_min:,.0f} ‚Ç¨".replace(",", " ") if vf_min is not None else "‚Äî"
        )
    with k7:
        st.metric(
            "Valeur fonci√®re max",
            f"{vf_max:,.0f} ‚Ç¨".replace(",", " ") if vf_max is not None else "‚Äî"
        )
    with k8:
        st.metric(
            "Max lignes / mutation",
            format_int(int(max_lines_per_mut)) if max_lines_per_mut is not None else "‚Äî"
        )
    st.image(
        "streamlit/assets/images/map_ventes_full_2020.png",
        use_container_width=False
    )
    st.warning(
        """
        - Dataset lourd (bcp de lignes et de colonnes).
        - Les valeurs fonci√®res extr√™mes (min / max) peuvent indiquer des mutations particuli√®res 
        (dons, mutations mixtes et/ou composite).
        - Pr√©sence de mutations dans les DROM/COM (Guadeloupe, R√©union, ‚Ä¶) et en Corse.
        - Absence des mutations en Alsace-Moselle (R√©gime sp√©cial).  
        **Point important :** dans DVF, une ligne ne correspond pas toujours √† un bien unique.
        DVF d√©crit des **mutations** (transactions) pouvant comporter plusieurs lignes (lots, d√©pendances, parcelles‚Ä¶).
        """
    )
    if max_lines_per_mut is not None:
        with st.expander("Voir un exemple de mutation avec beaucoup de lignes"):
            # On r√©cup√®re un id_mutation qui atteint le max (ou proche)
            sizes = df.groupby("id_mutation").size()
            example_id = sizes.sort_values(ascending=False).index[0]
            st.write(f"Exemple id_mutation : **{example_id}** (nb lignes = {int(sizes.loc[example_id])})")
            st.dataframe(df[df["id_mutation"] == example_id].head(30), width="stretch")


# =========================
# Section 2 ‚Äî Schema / Missingness
# =========================
with tab2:
    st.header("2) Structure des colonnes et valeurs manquantes")

    schema = df_schema(df)

    left, right = st.columns([1.3, 1])
    with left:
        st.markdown("**Sch√©ma des colonnes (type, manquants, cardinalit√©)**")
        st.dataframe(schema.sort_values("taux_manquant_%", ascending=False), width="stretch", height=420)

    with right:
        st.markdown("**Top colonnes les plus manquantes**")
        st.dataframe(top_missing(df, k=20), width="stretch", height=420)

    st.warning(
        "√Ä ce stade, l‚Äôobjectif est uniquement descriptif : la pr√©sence de valeurs manquantes et la diversit√© des types "
        "sont des signaux importants pour la suite (nettoyage, filtrage, agr√©gation)."
    )

# =========================
# Section 3 ‚Äî Quantitative variables
# =========================
with tab3:
    st.header("3) Variables quantitatives (num√©riques)")


    # --- 3.1 Nombre de pi√®ces principales ---
    st.subheader("3.1) Distribution du nombre de pi√®ces principales")

    if "nombre_pieces_principales" not in df.columns:
        st.warning("La colonne `nombre_pieces_principales` n'est pas pr√©sente dans le dataset.")
    else:
        s = df["nombre_pieces_principales"].dropna()

        # Optionnel : filtrage l√©ger pour lisibilit√© (souvent 0‚Äì10)
        s_plot = s[(s >= 0) & (s <= 10)]

        fig = px.histogram(
            s_plot,
            nbins=11,
            title="Nombre de pi√®ces principales (0 √† 10)",
            labels={"value": "nombre_pieces_principales", "count": "Fr√©quence"}
        )
        fig.update_layout(bargap=0.05)
        st.plotly_chart(fig, width="stretch")


        st.warning(
            "Le nombre de pi√®ces principales donne une lecture rapide de la typologie des mutations."
        )

    # --- 3.2 Top 10 codes postaux ---
    st.subheader("3.2) Top 10 des d√©partements les plus repr√©sent√©s")

    if "code_departement" not in df.columns:
        st.warning("La colonne `code_departement` n'est pas pr√©sente dans le dataset.")
    else:
        dep = df["code_departement"].dropna().astype(str)

        # IMPORTANT : ne pas zfill sur 3 chiffres (ex: 2A/2B n'existent pas en m√©tropole DVF standard)
        # On garde tel quel, et on nettoie juste les ".0" si la colonne est float
        dep = dep.str.replace(r"\.0$", "", regex=True)

        top10_dep = (
            dep.value_counts()
            .head(10)
            .reset_index()
        )
        top10_dep.columns = ["code_departement", "count"]

        # forcer l'ordre (du plus fr√©quent au moins fr√©quent)
        order = top10_dep.sort_values("count", ascending=False)["code_departement"].tolist()

        fig = px.bar(
            top10_dep,
            x="code_departement",
            y="count",
            category_orders={"code_departement": order},
            title="Top 10 des d√©partements par fr√©quence",
            labels={"code_departement": "Code d√©partement", "count": "Nombre de lignes"},
            text="count"
        )
        fig.update_traces(textposition="inside")
        fig.update_layout(xaxis_type="category")  # üîë force cat√©goriel
        st.plotly_chart(fig, width="stretch")

        with st.expander("Afficher le d√©tail (table)"):
            top10_dep["proportion_%"] = (top10_dep["count"] / top10_dep["count"].sum() * 100).round(2)
            st.dataframe(top10_dep, width="stretch")

        st.warning(
            "Les distributions num√©riques sont souvent asym√©triques dans DVF et peuvent contenir des valeurs extr√™mes. "
            "Cette observation motive des analyses plus pouss√©es avant mod√©lisation."
        )

# =========================
# Section 4 ‚Äî Cat√©gorielles (MODIFI√âE)
# =========================
with tab4:
    st.header("4) Variables cat√©gorielles ‚Äî r√©partition (%)")

    st.markdown(
        """
        On analyse ici deux variables cat√©gorielles structurantes :
        - **nature_mutation** : type d‚Äô√©v√©nement enregistr√© (vente, VEFA, √©change, adjudication, ‚Ä¶)
        - **type_local** : type de bien (appartement, maison, d√©pendance, ‚Ä¶)
        """
    )

    def plot_cat_percent(df: pd.DataFrame, col: str, top_k: int = 15, title: str = ""):
        if col not in df.columns:
            st.warning(f"La colonne `{col}` n'est pas pr√©sente dans le dataset.")
            return

        s = df[col].copy()

        # Normaliser l'affichage des NaN
        s = s.astype("object")
        s = s.where(~s.isna(), other="NaN")

        # R√©partition en %
        vc = (s.value_counts(normalize=True) * 100).round(3)

        # Top K modalit√©s
        vc_top = vc.head(top_k).reset_index()
        vc_top.columns = [col, "pourcentage"]

        # Ordre d√©croissant (plus fr√©quent -> moins fr√©quent)
        order = vc_top.sort_values("pourcentage", ascending=False)[col].tolist()

        fig = px.bar(
            vc_top,
            x=col,
            y="pourcentage",
            category_orders={col: order},
            title=title if title else f"R√©partition de {col} (Top {top_k})",
            labels={col: col, "pourcentage": "Pourcentage (%)"},
            text="pourcentage"
        )
        fig.update_traces(texttemplate="%{text:.2f}%", textposition="inside")
        fig.update_layout(
            xaxis_type="category",
            yaxis_ticksuffix="%",
            uniformtext_minsize=8,
            uniformtext_mode="hide",
            margin=dict(t=60, b=90)
        )
        fig.update_xaxes(tickangle=-30)

        st.plotly_chart(fig, width="stretch")

        with st.expander(f"Afficher le d√©tail ‚Äî {col}"):
            detail = s.value_counts(dropna=False).rename("count").reset_index().rename(columns={"index": col})
            detail["pourcentage_%"] = (detail["count"] / detail["count"].sum() * 100).round(3)
            st.dataframe(detail, width="stretch")

    # --- nature_mutation ---
    st.subheader("4.1) R√©partition de la nature de mutation")
    plot_cat_percent(
        df,
        col="nature_mutation",
        top_k=10
    )

    # --- type_local ---
    st.subheader("4.2) R√©partition du type de local")
    plot_cat_percent(
        df,
        col="type_local",
        top_k=10
    )
    st.warning(
        """
        On observe une majorit√© de mutations de type 'Vente' (90,74%).  
        La r√©partition des types de locaux est assez d√©s√©quilibr√©e avec un majorit√© de NaN et une r√©partition 
        relativement √©quilibr√©e enter maison, appartement et d√©pendance.
        """
    )
# =========================
# Section 5 ‚Äî First takeaways
# =========================
with tab5:
    st.header("5) Premiers constats")

    st.warning(
        """
        Cette exploration du dataset brut met en √©vidence plusieurs √©l√©ments structurants :

        - **H√©t√©rog√©n√©it√© des variables** : montants, surfaces, cat√©gories administratives.
        - **Valeurs manquantes** parfois tr√®s importantes voir majoritaire sur certaines colonnes.
        - **Granularit√© DVF** : la transaction (‚Äúmutation‚Äù) peut √™tre d√©crite sur plusieurs lignes.
        - **Distributions asym√©triques** et valeurs extr√™mes possibles sur les variables num√©riques.

        üëâ Ces constats justifient les √©tapes suivantes : compr√©hension des mutations, filtrage du p√©rim√®tre
        (ventes, appartements), puis pr√©paration d‚Äôun dataset exploitable pour l‚Äôanalyse et la mod√©lisation.
        """
    )

